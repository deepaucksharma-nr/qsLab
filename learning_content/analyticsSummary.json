{
  "lessons": [
    {
      "lessonId": "LESSON_00_INTRODUCTION_V2",
      "title": "Course Introduction & Setup",
      "totalEstimatedDuration": "10 minutes",
      "learningObjectives": [
        "Understand the course structure and micro-learning approach",
        "Identify the three main pillars of the course",
        "Set expectations for hands-on learning with Kafka 4.0+ Share Groups"
      ],
      "episodes": [
        {
          "episodeId": "EPISODE_00_01_COURSE_OVERVIEW_V2",
          "title": "Welcome to Your Kafka Monitoring Journey",
          "order": 1,
          "estimatedDuration": "5 minutes",
          "learningObjectives": [
            "Recognize the importance of understanding 'why' behind metrics",
            "Identify Share Groups as a key innovation in Kafka 4.0+"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_00_01_WELCOME_V2",
              "episodeId": "EPISODE_00_01_COURSE_OVERVIEW_V2",
              "order": 1,
              "segmentType": "course_opening",
              "title": "Welcome and Setting the Scene",
              "learningObjectives": [
                "Feel welcomed and prepared for the learning journey"
              ],
              "textContent": "Welcome, New Relic engineers! Grab your favorite beverage and settle in for the next few hours as we embark on a deep dive into the world of Kafka monitoring.",
              "estimatedDuration": "10s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG00_01_WELCOME_V2",
                "visualIds": ["VISUAL_INTRO_01_01_TITLE_V2"]
              },
              "keywords": ["Welcome", "Kafka Monitoring", "New Relic"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_00_02_YOUR_GUIDE_V2",
              "episodeId": "EPISODE_00_01_COURSE_OVERVIEW_V2",
              "order": 2,
              "segmentType": "instructor_introduction",
              "title": "Your Guide and Journey Overview",
              "learningObjectives": [
                "Recognize the main topics covered in the course",
                "Understand the role of Kafka 4.0 Share Groups as a key focus area"
              ],
              "textContent": "I'm your guide through this journey, and together we'll explore everything from Kafka's fundamental concepts to the exciting new Share Groups feature that's now available in Kafka 4.0 as an early access preview.",
              "estimatedDuration": "45s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG00_02_GUIDE_V2",
                "visualIds": ["VISUAL_JOURNEY_MAP_V2"]
              },
              "interactiveCue": {
                "cueType": "pause_and_reflect",
                "promptText": "Before we show the full journey, can you recall the three main pillars of this course?",
                "triggerAtSeconds": 20,
                "revealDelay": 5
              },
              "keywords": ["Journey", "Share Groups", "Kafka 4.0", "Early Access"],
              "analytics": {
                "xapiEnabled": true,
                "trackTimeSpent": true,
                "interactionsToTrack": ["interactiveCue_response", "visual_hover_VISUAL_JOURNEY_MAP_V2"]
              },
              "pointsAwarded": 10
            }
          ],
          "checkpointId": "CHECKPOINT_EP00_01_INTRO_V2",
          "summaryReelAssetId": null,
          "completionCriteria": {
            "minSegmentsViewed": 2,
            "checkpointPassed": true
          }
        }
      ]
    },
    {
      "lessonId": "LESSON_01_KAFKA_FUNDAMENTALS_V2",
      "title": "Chapter 1: Kafka Fundamentals & The Rise of Share Groups",
      "totalEstimatedDuration": "70-90 minutes",
      "learningObjectives": [
        "Articulate the core problems Kafka was designed to solve",
        "Describe the key components of Kafka architecture",
        "Explain the limitations of traditional consumer groups that led to Share Groups",
        "Define Kafka 4.0+ Share Groups and their key semantic differences"
      ],
      "episodes": [
        {
          "episodeId": "EPISODE_01_01_WHY_KAFKA_V2",
          "title": "Episode 1: Why Kafka Exists - The Genesis",
          "order": 1,
          "estimatedDuration": "7 minutes",
          "learningObjectives": [
            "Describe the data integration challenges at LinkedIn circa 2010",
            "Explain how Kafka emerged as a solution to handle massive real-time data streams"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_01_01_01_LINKEDIN_2010_V2",
              "episodeId": "EPISODE_01_01_WHY_KAFKA_V2",
              "order": 1,
              "segmentType": "historical_context",
              "title": "The LinkedIn Data Crisis of 2010",
              "learningObjectives": [
                "Visualize the complexity of point-to-point data integrations",
                "Understand the maintenance nightmare of traditional approaches"
              ],
              "textContent": "Picture this: It's 2010 at LinkedIn. The engineering team is drowning in point-to-point data pipelines. Every new data integration looks like adding another strand to an already tangled ball of yarn. Sound familiar?",
              "estimatedDuration": "30s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_01_01_LINKEDIN_V2",
                "visualIds": ["VISUAL_01_01_01_TIMELINE_V2", "VISUAL_01_01_02_TANGLED_NETWORK_V2"]
              },
              "interactiveCue": {
                "cueType": "hover_to_explore",
                "promptText": "Hover over each connection to see the maintenance burden",
                "targetVisualId": "VISUAL_01_01_02_TANGLED_NETWORK_V2",
                "triggerAtSeconds": 15
              },
              "keywords": ["LinkedIn", "2010", "Point-to-point", "Data Pipeline"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_01_01_02_BIRTH_OF_KAFKA_V2",
              "episodeId": "EPISODE_01_01_WHY_KAFKA_V2",
              "order": 2,
              "segmentType": "origin_story",
              "title": "The Birth of Apache Kafka",
              "learningObjectives": [
                "Identify the fundamental problems Kafka was designed to solve"
              ],
              "textContent": "This is the world that gave birth to Apache Kafka. Kafka emerged to solve a fundamental problem: how do you handle massive streams of real-time data in a way that's scalable, fault-tolerant, and doesn't create a maintenance nightmare?",
              "estimatedDuration": "35s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_01_02_BIRTH_V2",
                "visualIds": ["VISUAL_01_01_03_PROBLEM_SOLUTION_V2"]
              },
              "keywords": ["Apache Kafka", "Problem", "Solution", "Real-time Data"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_01_01_03_NOT_JUST_QUEUE_V2",
              "episodeId": "EPISODE_01_01_WHY_KAFKA_V2",
              "order": 3,
              "segmentType": "paradigm_shift",
              "title": "Not Just Another Message Queue",
              "learningObjectives": [
                "Distinguish Kafka's approach from traditional message queues"
              ],
              "textContent": "The answer wasn't to build a better message queue—it was to reimagine messaging as a distributed, append-only log.",
              "estimatedDuration": "25s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_01_03_NOT_QUEUE_V2",
                "visualIds": ["VISUAL_01_01_04_QUEUE_VS_LOG_V2"]
              },
              "interactiveCue": {
                "cueType": "click_to_compare",
                "promptText": "Click to see messages disappear in a queue vs persist in Kafka",
                "targetVisualId": "VISUAL_01_01_04_QUEUE_VS_LOG_V2",
                "triggerAtSeconds": 10
              },
              "keywords": ["Message Queue", "Distributed Log", "Append-only"],
              "pointsAwarded": 10
            }
          ],
          "checkpointId": "CHECKPOINT_EP01_01_WHY_KAFKA_V2",
          "summaryReelAssetId": "REEL_EP01_KAFKA_BASICS_V2",
          "completionCriteria": {
            "minSegmentsViewed": 3,
            "checkpointPassed": true,
            "minInteractionsCompleted": 1
          },
          "badgeOnCompletion": "BADGE_KAFKA_FUNDAMENTALS_EP1_V2"
        },
        {
          "episodeId": "EPISODE_01_02_CORE_ARCH_PART1_V2",
          "title": "Episode 2: Kafka's Core - Topics, Partitions, Offsets",
          "order": 2,
          "estimatedDuration": "8 minutes",
          "learningObjectives": [
            "Define Kafka Topics and their role as data stream categories",
            "Explain Partitions as the unit of parallelism and scalability",
            "Describe Offsets as immutable pointers to messages"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_01_02_01_TOPICS_INTRO_V2",
              "episodeId": "EPISODE_01_02_CORE_ARCH_PART1_V2",
              "order": 1,
              "segmentType": "concept_introduction",
              "title": "Topics: The Books in Kafka's Library",
              "learningObjectives": [
                "Understand topics as logical categories of data streams"
              ],
              "textContent": "Let's start with topics. If Kafka is a library, topics are the individual books. Each topic represents a distinct stream of data—maybe 'user-clicks,' 'payment-transactions,' or 'sensor-readings.'",
              "estimatedDuration": "30s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_02_01_TOPICS_V2",
                "visualIds": ["VISUAL_01_02_01_LIBRARY_METAPHOR_V2"]
              },
              "keywords": ["Topics", "Library Metaphor", "Data Streams"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_01_02_03_PARTITIONS_INTRO_V2",
              "episodeId": "EPISODE_01_02_CORE_ARCH_PART1_V2",
              "order": 2,
              "segmentType": "scalability_concept",
              "title": "Enter Partitions: Kafka's Secret Weapon",
              "learningObjectives": [
                "Explain how partitions enable parallel processing"
              ],
              "textContent": "Enter partitions—Kafka's secret weapon for scalability. Imagine you're running a newspaper. Instead of having one massive printing press, you have multiple smaller presses, each printing different sections simultaneously. That's partitioning.",
              "estimatedDuration": "40s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_02_03_PARTITIONS_V2",
                "visualIds": ["VISUAL_01_02_03_NEWSPAPER_ANALOGY_V2"]
              },
              "interactiveCue": {
                "cueType": "drag_to_distribute",
                "promptText": "Drag articles to different printing presses to see parallelization",
                "targetVisualId": "VISUAL_01_02_03_NEWSPAPER_ANALOGY_V2",
                "triggerAtSeconds": 20
              },
              "keywords": ["Partitions", "Scalability", "Parallel Processing"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_01_02_05_OFFSET_CONCEPT_V2",
              "episodeId": "EPISODE_01_02_CORE_ARCH_PART1_V2",
              "order": 3,
              "segmentType": "immutability_concept",
              "title": "Offsets: Permanent Addresses for Messages",
              "learningObjectives": [
                "Understand offsets as immutable message identifiers"
              ],
              "textContent": "Here's where it gets interesting. Each partition is an ordered, immutable sequence of messages. When a message arrives, it gets an offset—think of it as a permanent street address. Partition 0, Offset 42 will always refer to the same message, forever.",
              "estimatedDuration": "45s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_02_05_OFFSETS_V2",
                "visualIds": ["VISUAL_01_02_05_OFFSET_ADDRESSING_V2"]
              },
              "keywords": ["Offset", "Permanent Address", "Immutable"],
              "pointsAwarded": 10
            }
          ],
          "checkpointId": "CHECKPOINT_EP01_02_CORE_ARCH_V2",
          "summaryReelAssetId": "REEL_EP01_CORE_ARCH_V2",
          "completionCriteria": {
            "minSegmentsViewed": 3,
            "checkpointPassed": true
          }
        },
        {
          "episodeId": "EPISODE_01_05_SHARE_GROUPS_INTRO_V2",
          "title": "Episode 5: Introducing Kafka 4.0+ Share Groups",
          "order": 5,
          "estimatedDuration": "8 minutes",
          "learningObjectives": [
            "Identify the limitations of traditional consumer groups",
            "Define Share Groups and their 'queue-like' semantics",
            "Explain the concept of cooperative consumption"
          ],
          "prerequisite": {
            "episodeIds": ["EPISODE_01_03_CONSUMER_GROUPS_V2", "EPISODE_01_04_CG_LIMITATIONS_V2"],
            "skipOption": {
              "quizId": "QUIZ_CONSUMER_GROUP_PROFICIENCY_V2",
              "passingScore": 80
            }
          },
          "segments": [
            {
              "segmentId": "SEGMENT_01_05_01_TRAD_LIMITS_RECAP_V2",
              "episodeId": "EPISODE_01_05_SHARE_GROUPS_INTRO_V2",
              "order": 1,
              "segmentType": "problem_recap",
              "title": "The Partition Ceiling Problem",
              "learningObjectives": [
                "Recall the strict consumer-to-partition coupling limitation"
              ],
              "textContent": "We've seen how traditional consumer groups hit a hard ceiling: you can't have more consumers than partitions. This creates the 'idle consumer' problem and limits elastic scaling.",
              "estimatedDuration": "30s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_05_01_LIMITS_V2",
                "visualIds": ["VISUAL_01_05_01_IDLE_CONSUMER_V2"]
              },
              "keywords": ["Partition Ceiling", "Idle Consumer", "Scaling Limitation"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_01_05_02_ENTER_SHARE_GROUPS_KIP932_V2",
              "episodeId": "EPISODE_01_05_SHARE_GROUPS_INTRO_V2",
              "order": 2,
              "segmentType": "feature_introduction",
              "title": "Enter Share Groups (KIP-932)",
              "learningObjectives": [
                "Understand Share Groups as Kafka's answer to queue-like consumption"
              ],
              "textContent": "February 2025 marked a watershed moment for Kafka with Share Groups (KIP-932) in early access. After two years of development, Kafka finally addresses use cases it's historically struggled with—true queue semantics within the Kafka ecosystem.",
              "estimatedDuration": "45s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_05_02_KIP932_V2",
                "visualIds": ["VISUAL_01_05_02_KIP932_TIMELINE_V2"]
              },
              "interactiveCue": {
                "cueType": "important_note",
                "promptText": "⚠️ Remember: Share Groups are EARLY ACCESS in Kafka 4.0. Not for production yet!",
                "triggerAtSeconds": 30,
                "displayDuration": 10
              },
              "keywords": ["Share Groups", "KIP-932", "Early Access", "Queue Semantics"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_01_05_03_COOPERATIVE_CONSUMPTION_V2",
              "episodeId": "EPISODE_01_05_SHARE_GROUPS_INTRO_V2",
              "order": 3,
              "segmentType": "concept_explanation",
              "title": "Cooperative Consumption Explained",
              "learningObjectives": [
                "Explain how multiple consumers can work on the same partition"
              ],
              "textContent": "The magic of Share Groups is cooperative consumption. Multiple consumers can now work on messages from the same partition simultaneously. It's like having multiple chefs at the same cooking station, each grabbing orders as they're ready.",
              "estimatedDuration": "50s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_05_03_COOPERATIVE_V2",
                "visualIds": ["VISUAL_01_05_03_KITCHEN_ANALOGY_V2"]
              },
              "interactiveCue": {
                "cueType": "simulation",
                "promptText": "Add more chefs and watch the order processing speed!",
                "targetVisualId": "VISUAL_01_05_03_KITCHEN_ANALOGY_V2",
                "triggerAtSeconds": 25
              },
              "keywords": ["Cooperative Consumption", "Parallel Processing", "Share Groups"],
              "pointsAwarded": 10
            }
          ],
          "checkpointId": "CHECKPOINT_EP01_05_SG_INTRO_V2",
          "summaryReelAssetId": "REEL_EP01_SG_INTRO_V2",
          "completionCriteria": {
            "minSegmentsViewed": 3,
            "checkpointPassed": true,
            "minInteractionsCompleted": 1
          }
        },
        {
          "episodeId": "EPISODE_01_06_SHARE_GROUP_METRICS_NEW_V2",
          "title": "Episode 6: Critical Share Group Metrics for 2025",
          "order": 6,
          "estimatedDuration": "7 minutes",
          "learningObjectives": [
            "Identify and define unacknowledged_age_ms for Share Groups",
            "Identify and define redelivery_count for Share Groups",
            "Identify and define max_lock_duration_ms for Share Groups"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_01_06_01_INTRO_SG_METRICS_V2",
              "episodeId": "EPISODE_01_06_SHARE_GROUP_METRICS_NEW_V2",
              "order": 1,
              "segmentType": "metrics_overview",
              "title": "Why Traditional Metrics Don't Work",
              "learningObjectives": [
                "Understand why offset lag is misleading for Share Groups"
              ],
              "textContent": "With Share Groups, traditional consumer lag becomes meaningless. A Share Group might show zero lag while hundreds of messages sit unacknowledged. We need entirely new metrics to understand queue health.",
              "estimatedDuration": "35s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_06_01_INTRO_METRICS_V2",
                "visualIds": ["VISUAL_01_06_01_ZERO_LAG_FALLACY_V2"]
              },
              "keywords": ["Zero Lag Fallacy", "Share Group Metrics", "Queue Health"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_01_06_02_UNACK_AGE_MS_V2",
              "episodeId": "EPISODE_01_06_SHARE_GROUP_METRICS_NEW_V2",
              "order": 2,
              "segmentType": "new_metric_deep_dive",
              "title": "Metric Deep Dive: unacknowledged_age_ms",
              "learningObjectives": [
                "Define unacknowledged_age_ms in the context of Share Groups",
                "Explain why this metric is critical for understanding queue-like lag"
              ],
              "textContent": "A crucial metric introduced with Share Groups is 'unacknowledged_age_ms'. This tracks the age of the oldest message that has been delivered to a consumer but not yet acknowledged. Think of it as the 'time-in-waiting' for your longest pending task.",
              "estimatedDuration": "60s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_06_02_UNACK_AGE_V2",
                "visualIds": ["VISUAL_METRIC_UNACK_AGE_GRAPH_V2", "VISUAL_COMPARISON_OFFSETLAG_VS_UNACKAGE_V2"]
              },
              "interactiveCue": {
                "cueType": "predict_value_change",
                "promptText": "If a consumer processing a message suddenly hangs indefinitely, what happens to unacknowledged_age_ms?",
                "options": ["Caps at timeout", "Resets to zero", "Grows continuously", "Stays constant"],
                "correctAnswer": 2,
                "triggerAtSeconds": 45
              },
              "keywords": ["unacknowledged_age_ms", "Share Group Metrics", "Queue Lag"],
              "analytics": {
                "xapiEnabled": true,
                "trackTimeSpent": true,
                "interactionsToTrack": ["interactiveCue_response"]
              },
              "pointsAwarded": 15
            },
            {
              "segmentId": "SEGMENT_01_06_03_REDELIVERY_COUNT_V2",
              "episodeId": "EPISODE_01_06_SHARE_GROUP_METRICS_NEW_V2",
              "order": 3,
              "segmentType": "new_metric_deep_dive",
              "title": "Metric Deep Dive: redelivery_count",
              "learningObjectives": [
                "Define redelivery_count and its implications",
                "Identify scenarios that cause high redelivery rates"
              ],
              "textContent": "The 'redelivery_count' metric tracks how many times messages have been redelivered after timeout or explicit release. High values indicate poison pills or processing failures. Unlike traditional Kafka, Share Groups track this per-message history.",
              "estimatedDuration": "55s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_06_03_REDELIVERY_V2",
                "visualIds": ["VISUAL_01_06_03_REDELIVERY_FLOW_V2"]
              },
              "keywords": ["redelivery_count", "Poison Pills", "Message Failures"],
              "pointsAwarded": 15
            },
            {
              "segmentId": "SEGMENT_01_06_04_MAX_LOCK_DURATION_V2",
              "episodeId": "EPISODE_01_06_SHARE_GROUP_METRICS_NEW_V2",
              "order": 4,
              "segmentType": "new_metric_deep_dive",
              "title": "Metric Deep Dive: max_lock_duration_ms",
              "learningObjectives": [
                "Define max_lock_duration_ms and its operational impact"
              ],
              "textContent": "The 'max_lock_duration_ms' shows the longest time any message has been locked by a consumer. This helps identify slow processors or hung consumers before they cause redeliveries. It's your early warning system.",
              "estimatedDuration": "50s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG01_06_04_LOCK_DURATION_V2",
                "visualIds": ["VISUAL_01_06_04_LOCK_TIMELINE_V2"]
              },
              "keywords": ["max_lock_duration_ms", "Consumer Health", "Early Warning"],
              "pointsAwarded": 15
            }
          ],
          "checkpointId": "CHECKPOINT_EP01_06_SG_METRICS_V2",
          "summaryReelAssetId": "REEL_EP01_SG_METRICS_V2",
          "completionCriteria": {
            "minSegmentsViewed": 4,
            "checkpointPassed": true,
            "minInteractionsCompleted": 1
          },
          "badgeOnCompletion": "BADGE_SHARE_GROUP_PIONEER_V2"
        }
      ]
    },
    {
      "lessonId": "LESSON_02_JMX_AND_METRIC_COLLECTION_V2",
      "title": "Chapter 2: JMX Monitoring & Modern Metric Collection",
      "totalEstimatedDuration": "70-80 minutes",
      "learningObjectives": [
        "Understand JMX architecture and its role in Java application monitoring",
        "Master Kafka's JMX metric hierarchy and Share Group MBeans",
        "Compare JMX exporters with Micrometer for modern applications",
        "Implement secure JMX monitoring practices"
      ],
      "episodes": [
        {
          "episodeId": "EPISODE_02_01_JMX_BASICS_V2",
          "title": "Episode 1: Understanding JMX - The Universal Java Monitor",
          "order": 1,
          "estimatedDuration": "7 minutes",
          "learningObjectives": [
            "Define JMX and its core components",
            "Explain MBeans and the MBean Server architecture",
            "Understand why JMX matters for Kafka monitoring"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_02_01_01_WHAT_IS_JMX_V2",
              "episodeId": "EPISODE_02_01_JMX_BASICS_V2",
              "order": 1,
              "segmentType": "technical_introduction",
              "title": "What is JMX and Why Should You Care?",
              "learningObjectives": [
                "Understand JMX as Java's built-in monitoring standard"
              ],
              "textContent": "If Kafka is a high-performance race car, JMX is the diagnostic port that lets you plug in and see what's happening under the hood. JMX—Java Management Extensions—is the standard way for Java applications to expose their internal state without special protocols.",
              "estimatedDuration": "40s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG02_01_01_JMX_INTRO_V2",
                "visualIds": ["VISUAL_02_01_01_RACECAR_DIAGNOSTIC_V2"]
              },
              "keywords": ["JMX", "Java Management Extensions", "Monitoring"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_02_01_02_MBEANS_EXPLAINED_V2",
              "episodeId": "EPISODE_02_01_JMX_BASICS_V2",
              "order": 2,
              "segmentType": "concept_explanation",
              "title": "MBeans: Your Window into Java Applications",
              "learningObjectives": [
                "Define MBeans and their attributes",
                "Understand the MBean naming hierarchy"
              ],
              "textContent": "At its core, JMX revolves around MBeans—Managed Beans. An MBean is just a Java object that exposes attributes (metrics) and operations (actions). Each MBean has a unique ObjectName following a pattern like: kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec",
              "estimatedDuration": "50s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG02_01_02_MBEANS_V2",
                "visualIds": ["VISUAL_02_01_02_MBEAN_HIERARCHY_V2"]
              },
              "interactiveCue": {
                "cueType": "interactive_explorer",
                "promptText": "Click on different parts of the MBean name to understand the hierarchy",
                "targetVisualId": "VISUAL_02_01_02_MBEAN_HIERARCHY_V2",
                "triggerAtSeconds": 30
              },
              "keywords": ["MBeans", "ObjectName", "Attributes"],
              "pointsAwarded": 10
            }
          ],
          "checkpointId": "CHECKPOINT_EP02_01_JMX_BASICS_V2",
          "summaryReelAssetId": "REEL_EP02_01_JMX_BASICS_V2"
        },
        {
          "episodeId": "EPISODE_02_02_KAFKA_JMX_METRICS_V2",
          "title": "Episode 2: Kafka's JMX Metric Hierarchy",
          "order": 2,
          "estimatedDuration": "8 minutes",
          "learningObjectives": [
            "Navigate Kafka's JMX metric categories",
            "Identify key broker, topic, and consumer metrics",
            "Locate the new Share Group MBeans in Kafka 4.0+"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_02_02_01_KAFKA_METRIC_CATEGORIES_V2",
              "episodeId": "EPISODE_02_02_KAFKA_JMX_METRICS_V2",
              "order": 1,
              "segmentType": "metric_taxonomy",
              "title": "Kafka's Metric Categories",
              "learningObjectives": [
                "Categorize Kafka metrics by their MBean domains"
              ],
              "textContent": "Kafka exposes hundreds of MBeans, organized logically. Broker-level metrics live under kafka.server, network metrics under kafka.network, and our new Share Group metrics? They're under kafka.server:type=share-group-metrics.",
              "estimatedDuration": "45s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG02_02_01_CATEGORIES_V2",
                "visualIds": ["VISUAL_02_02_01_METRIC_TREE_V2"]
              },
              "keywords": ["Metric Categories", "MBean Domains", "Share Group Metrics"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_02_02_02_SHARE_GROUP_MBEANS_V2",
              "episodeId": "EPISODE_02_02_KAFKA_JMX_METRICS_V2",
              "order": 2,
              "segmentType": "new_feature_discovery",
              "title": "Finding Share Group MBeans",
              "learningObjectives": [
                "Locate Share Group metrics in the JMX hierarchy",
                "Understand the structure of Share Group MBean names"
              ],
              "textContent": "Share Group metrics follow this pattern: kafka.server:type=share-group-metrics,group={groupId},topic={topic},partition={partition}. Each combination tracks unacknowledged messages, age metrics, and redelivery counts for that specific scope.",
              "estimatedDuration": "60s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG02_02_02_SG_MBEANS_V2",
                "visualIds": ["VISUAL_02_02_02_SG_MBEAN_PATTERN_V2"]
              },
              "interactiveCue": {
                "cueType": "code_completion",
                "promptText": "Complete the MBean name for Share Group 'payment-processors' on topic 'orders'",
                "template": "kafka.server:type=share-group-metrics,group=___,topic=___,partition=0",
                "correctAnswer": "payment-processors,orders",
                "triggerAtSeconds": 40
              },
              "keywords": ["Share Group MBeans", "Metric Pattern", "JMX Naming"],
              "pointsAwarded": 15
            }
          ],
          "checkpointId": "CHECKPOINT_EP02_02_KAFKA_METRICS_V2",
          "summaryReelAssetId": "REEL_EP02_02_KAFKA_METRICS_V2"
        },
        {
          "episodeId": "EPISODE_02_03_MICROMETER_VS_JMXEXPORTER_V2",
          "title": "Episode 3: Modern Metrics - Micrometer vs JMX Exporters",
          "order": 3,
          "estimatedDuration": "8 minutes",
          "learningObjectives": [
            "Compare Micrometer with raw JMX exporters for Spring-based Kafka applications",
            "Understand when to use each approach",
            "Configure Micrometer for Kafka Share Group metrics"
          ],
          "prerequisite": {
            "knowledgeCheck": {
              "question": "Are you familiar with Spring Boot applications?",
              "ifNo": "Review Spring Boot basics before this episode"
            }
          },
          "segments": [
            {
              "segmentId": "SEGMENT_02_03_01_MICROMETER_INTRO_V2",
              "episodeId": "EPISODE_02_03_MICROMETER_VS_JMXEXPORTER_V2",
              "order": 1,
              "segmentType": "technology_comparison",
              "title": "Enter Micrometer: Modern Metrics for Spring",
              "learningObjectives": [
                "Understand Micrometer as a metrics facade",
                "Identify its advantages for Spring Boot applications"
              ],
              "textContent": "While JMX exporters work great for traditional Kafka deployments, modern Spring Boot applications often use Micrometer. Think of Micrometer as a universal translator—it speaks to Prometheus, New Relic, DataDog, and more, all from one consistent API.",
              "estimatedDuration": "50s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG02_03_01_MICROMETER_V2",
                "visualIds": ["VISUAL_02_03_01_MICROMETER_ARCH_V2"]
              },
              "keywords": ["Micrometer", "Spring Boot", "Metrics Facade"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_02_03_02_CONFIGURING_MICROMETER_KAFKA_V2",
              "episodeId": "EPISODE_02_03_MICROMETER_VS_JMXEXPORTER_V2",
              "order": 2,
              "segmentType": "practical_configuration",
              "title": "Configuring Micrometer for Kafka Metrics",
              "learningObjectives": [
                "Configure Micrometer to expose Kafka metrics",
                "Add custom meters for Share Group metrics"
              ],
              "textContent": "Here's the power move: Micrometer can automatically bind to Kafka's JMX metrics AND let you add custom meters for Share Group specifics. Let me show you a Spring Boot configuration that captures both traditional and Share Group metrics.",
              "estimatedDuration": "75s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG02_03_02_CONFIG_V2",
                "visualIds": ["VISUAL_02_03_02_MICROMETER_CONFIG_V2"]
              },
              "codeExample": {
                "language": "java",
                "snippet": "@Configuration\npublic class KafkaMetricsConfig {\n    @Bean\n    public MeterBinder kafkaShareGroupMetrics() {\n        return registry -> {\n            // Custom gauge for unacknowledged_age_ms\n            Gauge.builder(\"kafka.sharegroup.unacked.age\", \n                () -> getOldestUnackedAge())\n                .tag(\"group\", \"payment-processors\")\n                .register(registry);\n        };\n    }\n}",
                "highlightLines": [5, 6, 7]
              },
              "keywords": ["Micrometer Configuration", "Custom Meters", "Share Group Metrics"],
              "pointsAwarded": 15
            },
            {
              "segmentId": "SEGMENT_02_03_03_CHOOSING_APPROACH_V2",
              "episodeId": "EPISODE_02_03_MICROMETER_VS_JMXEXPORTER_V2",
              "order": 3,
              "segmentType": "decision_framework",
              "title": "Choosing Your Metrics Strategy",
              "learningObjectives": [
                "Decide when to use JMX exporters vs Micrometer",
                "Understand trade-offs of each approach"
              ],
              "textContent": "So when should you use what? JMX exporters are perfect for broker-side metrics and legacy systems. Micrometer shines in Spring Boot applications where you're already in the Java ecosystem. The key is consistency across your monitoring stack.",
              "estimatedDuration": "60s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG02_03_03_CHOOSING_V2",
                "visualIds": ["VISUAL_02_03_03_DECISION_MATRIX_V2"]
              },
              "interactiveCue": {
                "cueType": "scenario_selection",
                "promptText": "Which approach would you choose for a Spring Boot Kafka Streams application?",
                "scenarios": [
                  "Legacy Kafka cluster with no application changes allowed",
                  "New Spring Boot microservice with custom Share Group logic",
                  "Kafka Connect deployment with standard connectors"
                ],
                "correctAnswers": ["JMX Exporter", "Micrometer", "JMX Exporter"],
                "triggerAtSeconds": 40
              },
              "keywords": ["Decision Framework", "JMX vs Micrometer", "Best Practices"],
              "pointsAwarded": 10
            }
          ],
          "checkpointId": "CHECKPOINT_EP02_03_MICROMETER_V2",
          "summaryReelAssetId": "REEL_EP02_03_MICROMETER_V2",
          "badgeOnCompletion": "BADGE_METRICS_STRATEGIST_V2"
        }
      ]
    },
    {
      "lessonId": "LESSON_03_NEWRELIC_INTEGRATION_V2",
      "title": "Chapter 3: New Relic Integration & Queues/Streams UI v2",
      "totalEstimatedDuration": "60-70 minutes",
      "learningObjectives": [
        "Master QueueSample v2 schema with shareGroupId and processingMode",
        "Build custom OHIs for Share Group observability",
        "Leverage nri-flex for rapid metric collection",
        "Optimize the Queues & Streams UI for Share Group monitoring"
      ],
      "episodes": [
        {
          "episodeId": "EPISODE_03_01_QUEUESAMPLE_V2_SCHEMA_V2",
          "title": "Episode 1: Understanding QueueSample v2 Schema",
          "order": 1,
          "estimatedDuration": "7 minutes",
          "learningObjectives": [
            "Understand the QueueSample event structure",
            "Identify new v2 fields: shareGroupId and processingMode",
            "Map Kafka concepts to QueueSample attributes"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_03_01_01_QUEUESAMPLE_INTRO_V2",
              "episodeId": "EPISODE_03_01_QUEUESAMPLE_V2_SCHEMA_V2",
              "order": 1,
              "segmentType": "schema_introduction",
              "title": "QueueSample: The Universal Queue Language",
              "learningObjectives": [
                "Understand QueueSample as New Relic's queue abstraction"
              ],
              "textContent": "QueueSample events are New Relic's universal format for queue and stream metrics. Think of it as a common language that lets you compare apples to apples across Kafka, RabbitMQ, SQS, and more. But with v2, we get Share Group superpowers.",
              "estimatedDuration": "40s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG03_01_01_QS_INTRO_V2",
                "visualIds": ["VISUAL_03_01_01_QUEUE_ROSETTA_V2"]
              },
              "keywords": ["QueueSample", "Universal Format", "Queue Metrics"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_03_01_02_V2_NEW_FIELDS_V2",
              "episodeId": "EPISODE_03_01_QUEUESAMPLE_V2_SCHEMA_V2",
              "order": 2,
              "segmentType": "new_feature_highlight",
              "title": "New in v2: shareGroupId & processingMode",
              "learningObjectives": [
                "Define the shareGroupId field and its purpose",
                "Understand processingMode values and their meaning"
              ],
              "textContent": "The January 2025 QueueSample v2 update brings two critical fields for Share Groups. The 'shareGroupId' explicitly identifies which Share Group generated this sample. The 'processingMode' field distinguishes between 'share_group', 'consumer_group', or other queue types.",
              "estimatedDuration": "60s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG03_01_02_NEW_FIELDS_V2",
                "visualIds": ["VISUAL_NR_QUEUESAMPLE_V2_SCHEMA_HIGHLIGHT_V2"]
              },
              "interactiveCue": {
                "cueType": "field_mapping_exercise",
                "promptText": "Match the Kafka concept to the QueueSample field",
                "mappings": [
                  {"kafka": "Share Group Name", "correct": "shareGroupId"},
                  {"kafka": "Topic Name", "correct": "queueName"},
                  {"kafka": "Consumption Type", "correct": "processingMode"}
                ],
                "triggerAtSeconds": 45
              },
              "keywords": ["shareGroupId", "processingMode", "QueueSample v2"],
              "pointsAwarded": 15
            },
            {
              "segmentId": "SEGMENT_03_01_03_COMPLETE_EXAMPLE_V2",
              "episodeId": "EPISODE_03_01_QUEUESAMPLE_V2_SCHEMA_V2",
              "order": 3,
              "segmentType": "practical_example",
              "title": "Complete QueueSample v2 Example",
              "learningObjectives": [
                "Construct a complete QueueSample event for Share Groups"
              ],
              "textContent": "Let's build a complete QueueSample event for our payment-processors Share Group. Notice how we map Kafka metrics to queue concepts: unacknowledged messages become the queue depth, oldest unacked age becomes message age.",
              "estimatedDuration": "55s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG03_01_03_EXAMPLE_V2",
                "visualIds": ["VISUAL_03_01_03_COMPLETE_EVENT_V2"]
              },
              "codeExample": {
                "language": "json",
                "snippet": "{\n  \"eventType\": \"QueueSample\",\n  \"provider\": \"kafka\",\n  \"queueName\": \"orders\",\n  \"shareGroupId\": \"payment-processors\",\n  \"processingMode\": \"share_group\",\n  \"messageCount\": 145,\n  \"oldestMessageAge\": 32000,\n  \"throughputIn\": 523.4,\n  \"throughputOut\": 498.2,\n  \"errorRate\": 2.3,\n  \"clusterName\": \"prod-kafka-east\",\n  \"timestamp\": 1706803200000\n}",
                "animateTyping": true,
                "highlightNewFields": ["shareGroupId", "processingMode"]
              },
              "keywords": ["Complete Example", "Event Structure", "Field Mapping"],
              "pointsAwarded": 10
            }
          ],
          "checkpointId": "CHECKPOINT_EP03_01_SCHEMA_V2",
          "summaryReelAssetId": "REEL_EP03_01_SCHEMA_V2"
        },
        {
          "episodeId": "EPISODE_03_02_CUSTOM_OHI_DEVELOPMENT_V2",
          "title": "Episode 2: Building a Custom OHI for Share Groups",
          "order": 2,
          "estimatedDuration": "8 minutes",
          "learningObjectives": [
            "Design an OHI architecture for Share Group metrics",
            "Transform JMX data into QueueSample v2 events",
            "Handle high-cardinality metrics efficiently"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_03_02_01_OHI_ARCHITECTURE_V2",
              "episodeId": "EPISODE_03_02_CUSTOM_OHI_DEVELOPMENT_V2",
              "order": 1,
              "segmentType": "architecture_design",
              "title": "OHI Architecture for Share Groups",
              "learningObjectives": [
                "Design a scalable OHI architecture"
              ],
              "textContent": "Our custom OHI needs to bridge three worlds: scrape metrics from JMX or Prometheus endpoints, transform them into meaningful queue semantics, and emit both detailed diagnostic events and streamlined QueueSample v2 events for the UI.",
              "estimatedDuration": "50s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG03_02_01_ARCH_V2",
                "visualIds": ["VISUAL_03_02_01_OHI_ARCHITECTURE_V2"]
              },
              "keywords": ["OHI Architecture", "Integration Design", "Data Flow"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_03_02_02_TRANSFORMATION_LOGIC_V2",
              "episodeId": "EPISODE_03_02_CUSTOM_OHI_DEVELOPMENT_V2",
              "order": 2,
              "segmentType": "code_walkthrough",
              "title": "Transforming Metrics to QueueSample v2",
              "learningObjectives": [
                "Implement metric transformation logic",
                "Map JMX metrics to QueueSample fields"
              ],
              "textContent": "The heart of our OHI is the transformation logic. We aggregate per-partition metrics, calculate derived values like error rates, and ensure every QueueSample event has the new shareGroupId and processingMode fields properly set.",
              "estimatedDuration": "75s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG03_02_02_TRANSFORM_V2",
                "visualIds": ["VISUAL_03_02_02_TRANSFORM_FLOW_V2"]
              },
              "codeExample": {
                "language": "go",
                "snippet": "func transformToQueueSample(metrics ShareGroupMetrics) QueueSample {\n    return QueueSample{\n        EventType:      \"QueueSample\",\n        Provider:       \"kafka\",\n        QueueName:      metrics.Topic,\n        ShareGroupId:   metrics.GroupID,  // NEW v2 field\n        ProcessingMode: \"share_group\",     // NEW v2 field\n        MessageCount:   metrics.UnackedCount + metrics.AvailableCount,\n        OldestMessageAge: metrics.OldestUnackedAgeMs,\n        ErrorRate:      calculateErrorRate(metrics),\n    }\n}",
                "highlightLines": [6, 7],
                "executionDemo": true
              },
              "keywords": ["Transformation Logic", "Metric Mapping", "Go Code"],
              "pointsAwarded": 20
            }
          ],
          "checkpointId": "CHECKPOINT_EP03_02_OHI_DEV_V2",
          "summaryReelAssetId": "REEL_EP03_02_OHI_DEV_V2"
        },
        {
          "episodeId": "EPISODE_03_03_QUEUES_STREAMS_UI_V2",
          "title": "Episode 3: Mastering the Queues & Streams UI for Share Groups",
          "order": 3,
          "estimatedDuration": "7 minutes",
          "learningObjectives": [
            "Navigate the Queues & Streams UI with Share Group data",
            "Use shareGroupId filters effectively",
            "Create custom views for Share Group monitoring"
          ],
          "segments": [
            {
              "segmentId": "SEGMENT_03_03_01_UI_NAVIGATION_V2",
              "episodeId": "EPISODE_03_03_QUEUES_STREAMS_UI_V2",
              "order": 1,
              "segmentType": "ui_walkthrough",
              "title": "Navigating Share Groups in the UI",
              "learningObjectives": [
                "Find and filter Share Group queues in the UI"
              ],
              "textContent": "With our QueueSample v2 events flowing, the Queues & Streams UI comes alive. You can now filter by shareGroupId, compare different processingModes side-by-side, and get queue-specific insights that were impossible with traditional monitoring.",
              "estimatedDuration": "60s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG03_03_01_UI_NAV_V2",
                "visualIds": ["VISUAL_03_03_01_UI_OVERVIEW_V2", "VISUAL_03_03_01_FILTER_DEMO_V2"]
              },
              "interactiveCue": {
                "cueType": "ui_simulation",
                "promptText": "Try filtering by shareGroupId='payment-processors'",
                "simulationType": "interactive_ui_mockup",
                "triggerAtSeconds": 40
              },
              "keywords": ["UI Navigation", "Filtering", "Share Group Views"],
              "pointsAwarded": 10
            },
            {
              "segmentId": "SEGMENT_03_03_02_CUSTOM_DASHBOARDS_V2",
              "episodeId": "EPISODE_03_03_QUEUES_STREAMS_UI_V2",
              "order": 2,
              "segmentType": "advanced_customization",
              "title": "Building Share Group Dashboards",
              "learningObjectives": [
                "Create custom dashboard widgets for Share Groups",
                "Combine traditional and Share Group metrics"
              ],
              "textContent": "The real power comes from custom dashboards that combine traditional Kafka metrics with Share Group insights. Let me show you a dashboard that saved our team during a production incident by revealing the zero lag fallacy in real-time.",
              "estimatedDuration": "70s",
              "mediaRefs": {
                "audioId": "AUDIO_SEG03_03_02_DASHBOARDS_V2",
                "visualIds": ["VISUAL_03_03_02_CUSTOM_DASHBOARD_V2"]
              },
              "dashboardExample": {
                "widgets": [
                  {
                    "type": "comparison_chart",
                    "title": "Traditional Lag vs Share Group Reality",
                    "query1": "SELECT latest(consumerLag) FROM KafkaConsumerSample",
                    "query2": "SELECT latest(messageCount) FROM QueueSample WHERE processingMode='share_group'"
                  },
                  {
                    "type": "heatmap",
                    "title": "Share Group Health by Topic",
                    "query": "SELECT latest(oldestMessageAge) FROM QueueSample FACET queueName, shareGroupId"
                  }
                ]
              },
              "keywords": ["Custom Dashboards", "Widget Design", "Incident Response"],
              "pointsAwarded": 15
            }
          ],
          "checkpointId": "CHECKPOINT_EP03_03_UI_MASTERY_V2",
          "summaryReelAssetId": "REEL_EP03_03_UI_MASTERY_V2",
          "badgeOnCompletion": "BADGE_UI_MASTER_V2"
        }
      ]
    }
  ],
  "courseCompletion": {
    "certificateId": "CERT_KAFKA_MONITORING_2025_V2",
    "requirements": {
      "minEpisodesCompleted": 15,
      "minCheckpointsPassed": 12,
      "minBadgesEarned": 5,
      "minPoints": 3000
    },
    "completionRewards": {
      "certificate": {
        "title": "Kafka Share Groups Monitoring Expert",
        "issuer": "New Relic University",
        "skills": [
          "Kafka 4.0+ Share Groups",
          "Advanced JMX Monitoring",
          "Micrometer Integration",
          "QueueSample v2 Schema",
          "Custom OHI Development"
        ]
      },
      "badge": "BADGE_KAFKA_MONITORING_MASTER_V2",
      "slackAnnouncement": true,
      "linkedInShareable": true
    }
  },
  "supportingMaterials": {
    "quickReference": {
      "shareGroupMetrics": {
        "unacknowledged_age_ms": "Age of oldest unacked message",
        "redelivery_count": "Times a message has been redelivered",
        "max_lock_duration_ms": "Longest time a message has been locked"
      },
      "queueSampleV2Fields": {
        "shareGroupId": "Identifies the specific Share Group",
        "processingMode": "Values: 'share_group', 'consumer_group', etc."
      },
      "enableShareGroups": "share.groups.enabled=true\nunstable.api.versions.enable=true"
    },
    "troubleshootingGuide": {
      "commonIssues": [
        {
          "issue": "Share Group metrics not appearing",
          "checks": [
            "Verify share.groups.enabled=true",
            "Confirm Share Groups are actually being used",
            "Check JMX MBean existence"
          ]
        },
        {
          "issue": "QueueSample events missing shareGroupId",
          "checks": [
            "Verify OHI is emitting v2 schema",
            "Check transformation logic",
            "Confirm New Relic is on latest version"
          ]
        }
      ]
    },
    "labExercises": {
      "available": true,
      "githubRepo": "https://github.com/newrelic/kafka-share-groups-lab",
      "dockerCompose": true,
      "estimatedSetupTime": "15 minutes"
    }
  }
}