version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: week3-zookeeper
    hostname: zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_MAX_CLIENT_CNXNS: 60
      ZOOKEEPER_AUTOPURGE_SNAP_RETAIN_COUNT: 3
      ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: 24
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: INFO
      # Performance optimizations
      ZOOKEEPER_SNAP_COUNT: 100000
      ZOOKEEPER_GLOBAL_OUTSTANDING_LIMIT: 1000
    ports:
      - "32181:2181"
    volumes:
      - week3-zookeeper-data:/var/lib/zookeeper/data
      - week3-zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - week3-network
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181", "|", "grep", "imok"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  broker-1:
    image: confluentinc/cp-kafka:7.5.0
    container_name: week3-broker-1
    hostname: broker-1
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "39092:39092"
      - "9092:9092"
      - "9101:9101"
    environment:
      # Basic Configuration
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-1:9092,PLAINTEXT_HOST://localhost:39092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      
      # Replication Configuration for Multi-Broker
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      
      # Performance Optimization
      KAFKA_NUM_NETWORK_THREADS: 16
      KAFKA_NUM_IO_THREADS: 16
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 1048576
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 1048576
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_NUM_REPLICA_FETCHERS: 4
      KAFKA_REPLICA_FETCH_MAX_BYTES: 1048576
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 3000
      
      # Memory & GC Optimization
      KAFKA_HEAP_OPTS: "-Xmx2G -Xms2G"
      KAFKA_JVM_PERFORMANCE_OPTS: >-
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=20
        -XX:InitiatingHeapOccupancyPercent=35
        -XX:+ExplicitGCInvokesConcurrent
        -XX:MaxInlineLevel=15
        -Djava.awt.headless=true
      
      # JMX Configuration
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      
      # Log Configuration
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_CLEANUP_POLICY: "delete"
      KAFKA_COMPRESSION_TYPE: "lz4"
      
      # Additional Performance Settings
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_AUTO_LEADER_REBALANCE_ENABLE: 'true'
      KAFKA_LEADER_IMBALANCE_CHECK_INTERVAL_SECONDS: 300
      KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE: 'false'
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_LAG_TIME_MAX_MS: 30000
    volumes:
      - week3-broker-1-data:/var/lib/kafka/data
      - week3-broker-1-logs:/var/lib/kafka/logs
    networks:
      - week3-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  broker-2:
    image: confluentinc/cp-kafka:7.5.0
    container_name: week3-broker-2
    hostname: broker-2
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "39093:39093"
      - "9093:9093"
      - "9102:9102"
    environment:
      # Basic Configuration
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-2:9093,PLAINTEXT_HOST://localhost:39093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      
      # Replication Configuration
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      
      # Performance Optimization (same as broker-1)
      KAFKA_NUM_NETWORK_THREADS: 16
      KAFKA_NUM_IO_THREADS: 16
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 1048576
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 1048576
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_NUM_REPLICA_FETCHERS: 4
      KAFKA_REPLICA_FETCH_MAX_BYTES: 1048576
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 3000
      
      # Memory & GC Optimization
      KAFKA_HEAP_OPTS: "-Xmx2G -Xms2G"
      KAFKA_JVM_PERFORMANCE_OPTS: >-
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=20
        -XX:InitiatingHeapOccupancyPercent=35
        -XX:+ExplicitGCInvokesConcurrent
        -XX:MaxInlineLevel=15
        -Djava.awt.headless=true
      
      # JMX Configuration
      KAFKA_JMX_PORT: 9102
      KAFKA_JMX_HOSTNAME: localhost
      
      # Log Configuration
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_CLEANUP_POLICY: "delete"
      KAFKA_COMPRESSION_TYPE: "lz4"
      
      # Additional Settings
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_AUTO_LEADER_REBALANCE_ENABLE: 'true'
      KAFKA_LEADER_IMBALANCE_CHECK_INTERVAL_SECONDS: 300
      KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE: 'false'
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_LAG_TIME_MAX_MS: 30000
    volumes:
      - week3-broker-2-data:/var/lib/kafka/data
      - week3-broker-2-logs:/var/lib/kafka/logs
    networks:
      - week3-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9093"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: week3-kafka-ui
    restart: unless-stopped
    depends_on:
      broker-1:
        condition: service_healthy
      broker-2:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: week3-optimizer-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker-1:9092,broker-2:9093
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_JMXPORT: 9101
      KAFKA_CLUSTERS_0_READONLY: "false"
      DYNAMIC_CONFIG_ENABLED: "true"
      LOGGING_LEVEL_ROOT: INFO
    networks:
      - week3-network
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8080/actuator/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Performance testing tool
  kafka-load-generator:
    image: confluentinc/cp-kafka:7.5.0
    container_name: week3-load-generator
    restart: unless-stopped
    depends_on:
      broker-1:
        condition: service_healthy
      broker-2:
        condition: service_healthy
    environment:
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
    volumes:
      - ./load-scripts:/scripts
    command: tail -f /dev/null
    networks:
      - week3-network
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "2"

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: week3-prometheus
    restart: unless-stopped
    depends_on:
      - jmx-exporter-broker1
      - jmx-exporter-broker2
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=7d'
      - '--storage.tsdb.retention.size=5GB'
    networks:
      - week3-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # JMX Exporter for Broker 1
  jmx-exporter-broker1:
    image: sscaling/jmx-prometheus-exporter:0.18.0
    container_name: week3-jmx-exporter-broker1
    restart: unless-stopped
    depends_on:
      broker-1:
        condition: service_healthy
    ports:
      - "8090:8080"
    environment:
      JMX_PORT: 9101
      JMX_HOST: broker-1
    volumes:
      - ./jmx-exporter-config.yml:/etc/jmx-exporter/config.yml:ro
    networks:
      - week3-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "2"

  # JMX Exporter for Broker 2
  jmx-exporter-broker2:
    image: sscaling/jmx-prometheus-exporter:0.18.0
    container_name: week3-jmx-exporter-broker2
    restart: unless-stopped
    depends_on:
      broker-2:
        condition: service_healthy
    ports:
      - "8091:8080"
    environment:
      JMX_PORT: 9102
      JMX_HOST: broker-2
    volumes:
      - ./jmx-exporter-config.yml:/etc/jmx-exporter/config.yml:ro
    networks:
      - week3-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "2"

  # New Relic Infrastructure Agent
  newrelic-infra:
    image: newrelic/infrastructure:latest
    container_name: week3-newrelic-infra
    restart: unless-stopped
    depends_on:
      broker-1:
        condition: service_healthy
      broker-2:
        condition: service_healthy
    cap_add:
      - SYS_PTRACE
    network_mode: host
    pid: host
    privileged: true
    environment:
      NRIA_LICENSE_KEY: ${NEW_RELIC_LICENSE_KEY}
      NRIA_DISPLAY_NAME: "Week3-Optimizer-Lab"
      NRIA_CUSTOM_ATTRIBUTES: '{"cluster":"week3-optimizer","purpose":"performance-tuning","week":"3","lab_type":"optimization"}'
      NRIA_LOG_LEVEL: "info"
      NRIA_ENABLE_PROCESS_METRICS: true
      NRIA_METRICS_PROCESS_SAMPLE_RATE: 30
    volumes:
      - /:/host:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - ./configs:/etc/newrelic-infra/integrations.d:ro
      - newrelic-data:/var/db/newrelic-infra
    healthcheck:
      test: ["CMD", "newrelic-infra-ctl", "status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

volumes:
  week3-broker-1-data:
    driver: local
  week3-broker-1-logs:
    driver: local
  week3-broker-2-data:
    driver: local
  week3-broker-2-logs:
    driver: local
  week3-zookeeper-data:
    driver: local
  week3-zookeeper-logs:
    driver: local
  prometheus-data:
    driver: local
  newrelic-data:
    driver: local

networks:
  week3-network:
    name: week3-optimizer-network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.22.0.0/16